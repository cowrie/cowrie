{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78508f16-bcaf-4c0d-b825-3daba9a6f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96e52213-dc99-41ad-a36d-d7d50ee9c76d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29f7d09dc5284325afa1105080560e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "token = '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'\n",
    "\n",
    "model_name = \"google/codegemma-7b-it\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, token=token, device_map=\"auto\", load_in_8bit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301ce1d0-5e54-40a4-b4dd-64e0f0009856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on GPU: True\n",
      "Tokenizer is on GPU: True\n"
     ]
    }
   ],
   "source": [
    "# Check if model and tokenizer are on GPU\n",
    "print(\"Model is on GPU:\", next(model.parameters()).is_cuda)\n",
    "print(\"Tokenizer is on GPU:\", next(model.parameters()).is_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "862eb13a-629b-4002-92fe-30acc84e3b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to simulate handling commands\n",
    "def handle_command(command, current_directory):\n",
    "    parts = command.split()\n",
    "    if parts[0] == 'cd':\n",
    "        try:\n",
    "            os.chdir(parts[1])\n",
    "            current_directory = os.getcwd()\n",
    "            return f\"Changed directory to {current_directory}\", current_directory\n",
    "        except Exception as e:\n",
    "            return str(e), current_directory\n",
    "    elif parts[0] == 'pwd':\n",
    "        return current_directory, current_directory\n",
    "    elif parts[0] == 'ls':\n",
    "        try:\n",
    "            files = os.listdir(current_directory)\n",
    "            return \"\\n\".join(files), current_directory\n",
    "        except Exception as e:\n",
    "            return str(e), current_directory\n",
    "    elif parts[0] == 'cat':\n",
    "        try:\n",
    "            with open(parts[1], 'r') as file:\n",
    "                content = file.read()\n",
    "            return content, current_directory\n",
    "        except Exception as e:\n",
    "            return str(e), current_directory\n",
    "    elif parts[0] == 'echo':\n",
    "        return \" \".join(parts[1:]), current_directory\n",
    "    else:\n",
    "        return f\"Command not recognized: {command}\", current_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfa813b3-c271-4b38-8e13-1999c682b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to dynamically update the prompt based on user input and current directory\n",
    "def update_prompt(command, current_directory):\n",
    "    output, new_directory = handle_command(command, current_directory)\n",
    "    prompt = \"\"\"You are a Linux terminal simulator. Your task is to generate simulated outputs for various Linux commands. \n",
    "You may choose your own linux commands as input. \n",
    "However, make sure that the outputs generated for these commands are as realistic as a linux terminal would generate. Generate outputs and not the explanation of the command.\n",
    "Below are examples of different Linux commands and their typical outputs:\n",
    "\n",
    "Example 1:\n",
    "Command: ls\n",
    "Output:\n",
    "file1.txt\n",
    "patient.txt\n",
    "department.txt\n",
    "report.pdf\n",
    "data.csv\n",
    "\n",
    "Example 2:\n",
    "Command: cat patient.txt\n",
    "Output:\n",
    "Patient ID: 12345\n",
    "Name: John Doe\n",
    "Age: 45\n",
    "Condition: Stable\n",
    "\n",
    "Example 3:\n",
    "Command: echo \"Hello, World!\"\n",
    "Output:\n",
    "Hello, World!\n",
    "\n",
    "Example 4:\n",
    "Command: grep \"error\" logfile.txt\n",
    "Output:\n",
    "2023-06-19 14:23:34 ERROR Failed to connect to server\n",
    "2023-06-19 14:24:10 ERROR Timeout occurred\n",
    "\n",
    "Example 5:\n",
    "Command: ps\n",
    "Output:\n",
    "PID TTY          TIME CMD\n",
    " 1234 pts/0    00:00:01 bash\n",
    " 5678 pts/1    00:00:02 python\n",
    " 91011 pts/2    00:00:00 top\n",
    "\n",
    "Example 6:\n",
    "Command: cd /home/user\n",
    "Output:\n",
    "Changed directory to /home/user\n",
    "\n",
    "Example 7:\n",
    "Command: pwd\n",
    "Output:\n",
    "/home/user\n",
    "\n",
    "Example 8:\n",
    "Command: ls /home/user\n",
    "Output:\n",
    "documents\n",
    "downloads\n",
    "music\n",
    "pictures\n",
    "videos\n",
    "\n",
    "Example 9:\n",
    "Command: cat /home/user/documents/file.txt\n",
    "Output:\n",
    "This is the content of file.txt in the documents directory.\n",
    "\n",
    "According to the above examples given generate outputs for different Linux commands. \n",
    "For each command, provide a realistic output as shown in the examples above. Use the current directory context for commands like 'cd' and 'pwd'.\n",
    "\n",
    "Current Directory: {new_directory}\n",
    "\n",
    "Command: {command}\n",
    "Output:\n",
    "{output}\n",
    "\"\"\"\n",
    "    return prompt, new_directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e409ca-6d5b-482a-920e-6a6214930db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "007e4895-3eda-4e34-b0a3-37bfedf062d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize current directory\n",
    "current_directory = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31134550-f674-488a-9f25-36be666903bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate user input\n",
    "user_input = 'ls'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8edf2bb4-f78b-4f9b-a332-e8e27bc04677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update prompt dynamically\n",
    "prompt, current_directory = update_prompt(user_input, current_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72b0c81f-d69b-434e-93f6-586fb74b39fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the prompt\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ffca34f-3f42-4402-b9c3-4c467fd5a78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move input_ids to CUDA if available\n",
    "if torch.cuda.is_available():\n",
    "    inputs = {k: v.to('cuda') for k, v in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "098ae762-3eff-4c10-be7a-1d719c367a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manasa Gorugantu\\anaconda3\\envs\\cuda_env\\lib\\site-packages\\transformers\\models\\gemma\\modeling_gemma.py:573: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Generate outputs from the model with configured parameters\n",
    "outputs = model.generate(inputs['input_ids'], max_length=5000, num_return_sequences=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1364450a-bd4a-4726-a787-0f7b0c6c460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decode the generated outputs\n",
    "generated_sequence = tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "293b6a93-2f78-470b-8ba4-0e82fef030af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Linux Command Sequence:\n",
      "You are a Linux terminal simulator. Your task is to generate simulated outputs for various Linux commands. \n",
      "You may choose your own linux commands as input. \n",
      "However, make sure that the outputs generated for these commands are as realistic as a linux terminal would generate. Generate outputs and not the explanation of the command.\n",
      "Below are examples of different Linux commands and their typical outputs:\n",
      "\n",
      "Example 1:\n",
      "Command: ls\n",
      "Output:\n",
      "file1.txt\n",
      "patient.txt\n",
      "department.txt\n",
      "report.pdf\n",
      "data.csv\n",
      "\n",
      "Example 2:\n",
      "Command: cat patient.txt\n",
      "Output:\n",
      "Patient ID: 12345\n",
      "Name: John Doe\n",
      "Age: 45\n",
      "Condition: Stable\n",
      "\n",
      "Example 3:\n",
      "Command: echo \"Hello, World!\"\n",
      "Output:\n",
      "Hello, World!\n",
      "\n",
      "Example 4:\n",
      "Command: grep \"error\" logfile.txt\n",
      "Output:\n",
      "2023-06-19 14:23:34 ERROR Failed to connect to server\n",
      "2023-06-19 14:24:10 ERROR Timeout occurred\n",
      "\n",
      "Example 5:\n",
      "Command: ps\n",
      "Output:\n",
      "PID TTY          TIME CMD\n",
      " 1234 pts/0    00:00:01 bash\n",
      " 5678 pts/1    00:00:02 python\n",
      " 91011 pts/2    00:00:00 top\n",
      "\n",
      "Example 6:\n",
      "Command: cd /home/user\n",
      "Output:\n",
      "Changed directory to /home/user\n",
      "\n",
      "Example 7:\n",
      "Command: pwd\n",
      "Output:\n",
      "/home/user\n",
      "\n",
      "Example 8:\n",
      "Command: ls /home/user\n",
      "Output:\n",
      "documents\n",
      "downloads\n",
      "music\n",
      "pictures\n",
      "videos\n",
      "\n",
      "Example 9:\n",
      "Command: cat /home/user/documents/file.txt\n",
      "Output:\n",
      "This is the content of file.txt in the documents directory.\n",
      "\n",
      "According to the above examples given generate outputs for different Linux commands. \n",
      "For each command, provide a realistic output as shown in the examples above. Use the current directory context for commands like 'cd' and 'pwd'.\n",
      "\n",
      "Current Directory: C:\\Users\\Manasa Gorugantu\\Documents\n",
      "\n",
      "Command: ls\n",
      "Output:\n",
      ".ipynb_checkpoints\n",
      "Anaconda\n",
      "Codegemma-1.ipynb\n",
      "codegemma_current directory.ipynb\n",
      "Codegemma__commands.ipynb\n",
      "desktop.ini\n",
      "Filestructure generation.ipynb\n",
      "My Music\n",
      "My Pictures\n",
      "My Videos\n",
      "prompt_engg\n",
      "Python Scripts\n",
      "Tasks - cybergaurd ai.txt\n",
      "WindowsPowerShell\n",
      ".gitignore\n",
      "\n",
      "Command: pwd\n",
      "Output:\n",
      "/home/user\n",
      "\n",
      "Command: cd prompt_engg\n",
      "Output:\n",
      "Changed directory to /home/user/prompt_engg\n",
      "\n",
      "Command: pwd\n",
      "Output:\n",
      "/home/user/prompt_engg\n",
      "\n",
      "Command: ls\n",
      "Output:\n",
      "chatgpt_prompt_engineering.ipynb\n",
      "prompt_engineering_basics.ipynb\n",
      "prompt_engineering_techniques.ipynb\n",
      "\n",
      "Command: cat chatgpt_prompt_engineering.ipynb\n",
      "Output:\n",
      "(The content of the chatgpt_prompt_engineering.ipynb file is displayed)\n",
      "\n",
      "Command: cd ..\n",
      "Output:\n",
      "Changed directory to /home/user\n",
      "\n",
      "Command: pwd\n",
      "Output:\n",
      "/home/user\n",
      "\n",
      "Command: cd ..\n",
      "Output:\n",
      "Changed directory to /home/user\n",
      "\n",
      "Command: pwd\n",
      "Output:\n",
      "/home/user\n",
      "\n",
      "Command: cd C:\\Users\\Manasa Gorugantu\\Documents\n",
      "Output:\n",
      "Changed directory to C:\\Users\\Manasa Gorugantu\\Documents\n",
      "\n",
      "Command: pwd\n",
      "Output:\n",
      "C:\\Users\\Manasa Gorugantu\\Documents\n",
      "\n",
      "Command: ls\n",
      "Output:\n",
      ".ipynb_checkpoints\n",
      "Anaconda\n",
      "Codegemma-1.ipynb\n",
      "codegemma_current directory.ipynb\n",
      "Codegemma__commands.ipynb\n",
      "desktop.ini\n",
      "Filestructure generation.ipynb\n",
      "My Music\n",
      "My Pictures\n",
      "My Videos\n",
      "prompt_engg\n",
      "Python Scripts\n",
      "Tasks - cybergaurd ai.txt\n",
      "WindowsPowerShell\n",
      ".gitignore\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print or use the generated sequence\n",
    "print(\"Generated Linux Command Sequence:\")\n",
    "print(generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0cb588-aa60-4787-8cda-370180496fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cuda_env)",
   "language": "python",
   "name": "cuda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
